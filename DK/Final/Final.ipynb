{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royh21k/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/royh21k/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nba_py\n",
    "import nba_py.player\n",
    "import nba_py.game\n",
    "import nba_py.league\n",
    "import nba_py.shotchart\n",
    "import nba_py.team\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.cross_validation as cv\n",
    "import sklearn.grid_search as gs\n",
    "import sklearn.linear_model as lm\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create list of teams\n",
    "a = nba_py.team.TeamList().info()\n",
    "teamList = {}\n",
    "teamRoster = {}\n",
    "n = 0\n",
    "for i in a.ABBREVIATION:\n",
    "    if n == 30:\n",
    "        break\n",
    "    teamList[i] = [a.TEAM_ID[n]]\n",
    "    teamRoster[i] = {0:[], 1:[]}\n",
    "    n += 1\n",
    "#create list of players and insert them into rosters\n",
    "b = nba_py.player.PlayerList().info()\n",
    "playerList = {}\n",
    "n = 0\n",
    "for i in b.DISPLAY_FIRST_LAST:\n",
    "    playerList[i] = [b.PERSON_ID[n], b.TEAM_ABBREVIATION[n], b.TEAM_ID[n]]\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a df to merge opponent's gamelogs to the team gamelog \n",
    "OppGameLogs = pd.DataFrame({})\n",
    "for i in teamList.keys():\n",
    "    OppGameLogs = pd.concat([OppGameLogs, nba_py.team.TeamGameLogs(teamList[i][0]).info()], ignore_index= True)\n",
    "OppGameLogs.columns = 'Opp_' + OppGameLogs.columns\n",
    "OppGameLogs = OppGameLogs.drop(['Opp_GAME_DATE', 'Opp_MATCHUP', 'Opp_WL'], axis = 1)\n",
    "OppGameLogs = OppGameLogs.rename(columns = {'Opp_Game_ID': 'Game_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create team gamelogs and team averages and standard deviation tables\n",
    "teamGameLogs = {}\n",
    "teamAvgs = pd.DataFrame({})\n",
    "# teamStds = pd.DataFrame({})\n",
    "for i in teamList.keys():\n",
    "    temp = nba_py.team.TeamGameLogs(teamList[i][0]).info()\n",
    "    temp = pd.merge(temp, OppGameLogs.loc[OppGameLogs.Opp_Team_ID != teamList[i][0],: ], on = 'Game_ID')\n",
    "    temp.GAME_DATE = pd.to_datetime(temp.GAME_DATE)\n",
    "    d = temp.GAME_DATE\n",
    "    temp['DaysSinceLastGame'] = d - d[1:].append(d[-1:]).reset_index().GAME_DATE\n",
    "    temp['HA'] = temp.MATCHUP.apply(lambda x: 'H' if 'vs.' in x else 'A')\n",
    "    temp['TEAM'] = temp.MATCHUP.apply(lambda x: x[:3])\n",
    "    temp['OPP_TEAM'] = temp.MATCHUP.apply(lambda x: x[-3:])\n",
    "    temp = temp.drop(['Team_ID', 'Game_ID', 'Opp_Team_ID', 'MATCHUP'], axis = 1)\n",
    "    teamGameLogs[i] = temp\n",
    "#     teamGameLogs[i].to_csv( i + 'gamelogs.csv')\n",
    "    tempAVG = pd.DataFrame(temp.mean()).transpose().drop(['W', 'L', 'Opp_W', 'Opp_L'], axis = 1)\n",
    "    tempAVG['TEAM'] = i\n",
    "#     tempSTD = pd.DataFrame(temp.std()).transpose().drop(['W', 'L', 'Opp_W', 'Opp_L'], axis = 1)\n",
    "#     tempSTD['TEAM'] = i\n",
    "    teamAvgs = pd.concat([teamAvgs,tempAVG], ignore_index= True)\n",
    "#     teamStds = pd.concat([teamStds,tempSTD], ignore_index= True)\n",
    "teamAvgs.columns = 'AVG_' + teamAvgs.columns\n",
    "teamAvgs = teamAvgs.rename(columns = {'AVG_TEAM': 'TEAM'})\n",
    "# teamStds.columns = 'STD_' + teamStds.columns\n",
    "# teamStds = teamStds.rename(columns = {'STD_TEAM': 'TEAM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to merge team vs opponent stats to player gamelogs\n",
    "avgoppcols = [c for c in teamAvgs.columns if '_Opp_' in c]\n",
    "avgteamcols = [c for c in teamAvgs.columns if (not ('_Opp_' in c) and ('AVG_'in c))]\n",
    "def teamOppstats(team, opp):\n",
    "    new_df = pd.DataFrame({})\n",
    "    for i in range(len(team)):\n",
    "        x = teamAvgs.loc[teamAvgs.TEAM == team[i], avgteamcols]\n",
    "        x.columns = [c.replace('AVG_', '') for c in x.columns]\n",
    "        y = teamAvgs.loc[teamAvgs.TEAM == opp[i], avgoppcols]\n",
    "        y.columns = [c.replace('AVG_Opp_', '') for c in y.columns]\n",
    "        z = x.reset_index(drop= True) - y.reset_index(drop = True)\n",
    "        z.columns = 'TEAM_OPP_' + z.columns\n",
    "        new_df = pd.concat([new_df, z], ignore_index=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to get rolling averages\n",
    "def pastavg(days, col):\n",
    "    new_col = []\n",
    "    for i in range(len(col)):\n",
    "        if i == len(col)-1:\n",
    "            new_col.append(col.mean())\n",
    "        else:\n",
    "            new_col.append(col[i+1:i+days+1].mean())\n",
    "    return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royh21k/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "roto = pd.read_csv('http://rotoguru1.com/cgi-bin/nba-dhd-2017.pl?&user=jasonjjchen&key=J8987209841',sep = ':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royh21k/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "roto1 = roto.iloc[:-1,:]\n",
    "roto1.loc[:,'Date'] = pd.to_datetime(roto1.Date.astype(int),format='%Y%m%d')\n",
    "# roto1 = roto1.iloc[2:,:] #remove na for unfinished games\n",
    "rotocols = roto1.columns[[1,2,3,4,5,6,8,9,10,11,12,16,24,25,31]]\n",
    "roto1 = roto1[rotocols] #clean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions to standardize names \n",
    "namechange = lambda x: x.replace('Derrick Jones', 'Derrick Jones, Jr.').replace('James Ennis', \\\n",
    "            'James Ennis III').replace('Guillermo Hernangomez', 'Willy Hernangomez').replace('Joseph Young', \\\n",
    "            'Joe Young').replace('Timothe Luwawu', 'Timothe Luwawu-Cabarrot').replace('Walter Tavares', \\\n",
    "            'Edy Tavares').replace('John Lucas', 'John Lucas III').replace('T.J. Warren', \\\n",
    "            'TJ Warren').replace('DeAndre Bembry', 'DeAndre\\' Bembry').replace('P.J. Tucker', \\\n",
    "            'PJ Tucker').replace('Larry Nance', 'Larry Nance Jr.').replace('C.J. Wilcox', \\\n",
    "            'CJ Wilcox').replace('C.J. McCollum', 'CJ McCollum').replace('Wes Matthews', \\\n",
    "            'Wesley Matthews').replace('J.J. Redick', 'JJ Redick').replace('K.J. McDaniels', \\\n",
    "            'KJ McDaniels').replace('A.J. Hammons', 'AJ Hammons').replace('Louis Williams', \\\n",
    "            'Lou Williams').replace('Wade Baldwin', 'Wade Baldwin IV').replace('Kelly Oubre', \\\n",
    "            'Kelly Oubre Jr.').replace('Johnny O\\'Bryant', 'Johnny O\\'Bryant III').replace('J.R. Smith', \\\n",
    "            'JR Smith').replace('C.J. Miles', 'CJ Miles').replace('R.J. Hunter', 'RJ Hunter').replace('Otto Porter', \\\n",
    "            'Otto Porter Jr.').replace('Jose Barea', 'J.J. Barea').replace('Ishmael Smith', \\\n",
    "            'Ish Smith').replace('Nene Hilario', 'Nene').replace('Maurice N\\'dour', 'Maurice Ndour')\n",
    "#function to standardize team abbreviations\n",
    "teamAbbrchange = lambda x: x.replace('atl', u'ATL').replace('bkn', u'BKN').replace('bos', u'BOS').replace('cha', \\\n",
    "            u'CHA').replace('chi', u'CHI').replace('cle', u'CLE').replace('dal', u'DAL').replace('den', \\\n",
    "            u'DEN').replace('det', u'DET').replace('gsw', u'GSW').replace('hou', u'HOU').replace('ind',\\\n",
    "            u'IND').replace('lac', u'LAC').replace('lal', u'LAL').replace('mem', u'MEM').replace('mia', \\\n",
    "            u'MIA').replace('mil', u'MIL').replace('min', u'MIN').replace('nor', u'NOP').replace('nyk', \\\n",
    "            u'NYK').replace('okc', u'OKC').replace('orl', u'ORL').replace('phi', u'PHI').replace('pho', \\\n",
    "            u'PHX').replace('por', u'POR').replace('sac', u'SAC').replace('sas', u'SAS').replace('tor', \\\n",
    "            u'TOR').replace('uta', u'UTA').replace('was', u'WAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roto1['First  Last'] = roto1['First  Last'].apply(namechange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean up draft kings data\n",
    "dkgamelog = roto1[-roto1['DK pos'].isnull()]\n",
    "dkgamelog = dkgamelog[-dkgamelog['Start'].isnull()]\n",
    "dkgamelog = dkgamelog.rename(columns = {'First  Last': 'PLAYER', 'Date': 'GAME_DATE'})\n",
    "dkgamelog['Start'] = dkgamelog['Start'].astype(int)\n",
    "temp = dkgamelog['DK pos'].astype(int).astype(str).str.join('@').str.get_dummies('@')\n",
    "temp.columns = 'POSITION:' + temp.columns\n",
    "# temp.columns = ['PG', 'SG', 'SF', 'PF', 'C']\n",
    "dkgamelog['DK pos'] = dkgamelog['DK pos'].astype(int).astype(str).str.join('@').str.split('@')\n",
    "dkgamelog = pd.concat([dkgamelog[['PLAYER', 'GAME_DATE', 'DK Sal', 'DK Change', 'DKP', 'Start', 'DK pos']], temp], axis= 1)\n",
    "dkgamelog.loc[dkgamelog['DK Change'].isnull(), 'DK Change'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modifying player gamelogs\n",
    "stats_cols = ['MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', \\\n",
    "              'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS', 'DKP', 'DD', 'TD']\n",
    "playerGameLogs = {}\n",
    "allPlayersGameLogs = pd.DataFrame({})\n",
    "playerAvgs = pd.DataFrame({})\n",
    "# playerStds = pd.DataFrame({})\n",
    "for i in playerList.keys():\n",
    "    temp = nba_py.player.PlayerGameLogs(playerList[i][0]).info()\n",
    "    if temp.shape[0] > 5: #limit to players who play more than 5 games\n",
    "#     try:\n",
    "#         temp = nba_py.player.PlayerGameLogs(playerList[i][0]).info()\n",
    "        temp.GAME_DATE = pd.to_datetime(temp.GAME_DATE)\n",
    "        temp['PLAYER'] = i\n",
    "        d = temp.GAME_DATE\n",
    "        temp['DaysSinceLastGame'] = d - d[1:].append(d[-1:]).reset_index().GAME_DATE\n",
    "        temp.loc[:, 'DaysSinceLastGame'] = (temp.loc[:, 'DaysSinceLastGame']/np.timedelta64(1, 'D')).astype(int)\n",
    "        temp['HA'] = temp.MATCHUP.apply(lambda x: 'H' if 'vs.' in x else 'A')\n",
    "        temp['TEAM'] = temp.MATCHUP.apply(lambda x: x[:3])\n",
    "        temp['OPP_TEAM'] = temp.MATCHUP.apply(lambda x: x[-3:])\n",
    "        temp['DOUBLES'] = (temp['PTS']>=10).astype(int) + (temp['REB']>=10).astype(int) + (temp['AST']>=10).astype(int) \\\n",
    "                        + (temp['STL']>=10).astype(int) + (temp['BLK']>=10).astype(int)\n",
    "        temp['DD'] = (temp['DOUBLES'] >= 2).astype(int)\n",
    "        temp['TD'] = (temp['DOUBLES'] >= 3).astype(int)\n",
    "#         temp = temp.drop(['SEASON_ID', 'Player_ID', 'Game_ID', 'VIDEO_AVAILABLE', 'MATCHUP', 'DOUBLES'], axis = 1)\n",
    "#         temp['DKPoints'] = temp['PTS'] + 0.5*temp['FG3M'] + 1.25*temp['REB'] + 1.5*temp['AST'] + 2*temp['STL'] - \\\n",
    "#                             0.5*temp['TOV'] + 2*temp['BLK'] + 1.5*temp['DD'] + 3*temp['TD']\n",
    "        temp = pd.merge(temp, dkgamelog, how = 'left', on = ['PLAYER', 'GAME_DATE'])\n",
    "        nulls = temp.Start.isnull()\n",
    "        if nulls.sum()>0:\n",
    "            for j in ['Start', 'POSITION:1', 'POSITION:2', 'POSITION:3', 'POSITION:4', 'POSITION:5']:\n",
    "                temp.loc[nulls, j] = round(temp[j].mean())\n",
    "            for j in ['DK Sal', 'DK Change']:\n",
    "                temp.loc[nulls, j] = round(temp[j].mean(), -2)\n",
    "            temp.loc[nulls, 'DKP'] = temp.loc[nulls, 'PTS'] + 0.5*temp.loc[nulls, 'FG3M'] + 1.25*temp.loc[nulls, 'REB'] + \\\n",
    "                                    1.5*temp.loc[nulls, 'AST'] + 2*temp.loc[nulls, 'STL'] - 0.5*temp.loc[nulls, 'TOV'] + \\\n",
    "                                    2*temp.loc[nulls, 'BLK'] + 1.5*temp.loc[nulls, 'DD'] + 3*temp.loc[nulls, 'TD']\n",
    "            posit = []\n",
    "            for j in range(nulls.sum()):\n",
    "                positions = ''\n",
    "                for k in ['POSITION:1', 'POSITION:2', 'POSITION:3', 'POSITION:4', 'POSITION:5']:\n",
    "                    if list(temp[nulls][k])[j] ==1.0:\n",
    "                        positions += k[-1:]\n",
    "                posit.append(positions)\n",
    "            temp.loc[nulls, 'DK pos'] = posit\n",
    "            temp.loc[nulls, 'DK pos'] = temp.loc[nulls, 'DK pos'].str.join('@').str.split('@')\n",
    "        for j in stats_cols:\n",
    "            temp['Past3_' + j] = pastavg(3, temp[j])\n",
    "            temp['Past6_' + j] = pastavg(6, temp[j])\n",
    "            temp['Avg_' + j] = pastavg(temp.shape[0], temp[j]) \n",
    "        temp2 = temp[stats_cols] \n",
    "        tempAVG = pd.DataFrame(temp2.mean()).transpose()\n",
    "        tempAVG['PLAYER'] = i\n",
    "#         tempSTD = pd.DataFrame(temp2.std()).transpose()\n",
    "#         tempSTD['PLAYER'] = i\n",
    "        playerAvgs = pd.concat([playerAvgs,tempAVG], ignore_index= True)\n",
    "#         playerStds = pd.concat([playerStds,tempSTD], ignore_index= True)\n",
    "        temp = pd.concat([temp, teamOppstats(temp.TEAM, temp.OPP_TEAM)], axis = 1)\n",
    "        allPlayersGameLogs = pd.concat([allPlayersGameLogs, temp], ignore_index= True)\n",
    "        playerGameLogs[i] = temp\n",
    "#         playerGameLogs[i].to_csv( i.replace(' ', '') + 'gamelogs.csv')\n",
    "#     except:\n",
    "#         i = i\n",
    "playerAvgs.columns = 'AVG_' + playerAvgs.columns\n",
    "playerAvgs = playerAvgs.rename(columns = {'AVG_PLAYER': 'PLAYER'})\n",
    "# playerStds.columns = 'STD_' + playerStds.columns\n",
    "# playerStds = playerStds.rename(columns = {'STD_PLAYER': 'PLAYER'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create team defense by position tables\n",
    "#dictionary keys are positions\n",
    "#dictionary 1 is similar to http://www.rotowire.com/daily/nba/defense-vspos.php?site=DraftKings&statview=season&pos=SG\n",
    "#dictionary 2 is similar to http://www.dfsgold.com/nba/defense-vs-position\n",
    "#need to add the information back to player gamelogs\n",
    "teamDefbyPOS = {}\n",
    "teamDefbyPOS2 = {}\n",
    "for i in range(1,6):\n",
    "    temp = allPlayersGameLogs.loc[allPlayersGameLogs['POSITION:' + str(i)] == 1, :]\n",
    "    temp.loc[temp.MIN == 0, 'MIN'] = 1\n",
    "    temp2 = temp[['OPP_TEAM', 'HA', 'DKP']]\n",
    "    temp2.loc[:, 'DKP'] = temp2.loc[:, 'DKP'].div(temp.MIN, axis = 'index')\n",
    "    x = temp2.groupby('OPP_TEAM')[['DKP']].mean()\n",
    "    x['League_Comparison'] = (x['DKP']/x.mean()[0]-1)*100\n",
    "    x = x.reset_index()\n",
    "    y = temp2[temp2.HA == 'H'].groupby('OPP_TEAM')[['DKP']].mean()\n",
    "    y['League_Comparison'] = (y['DKP']/y.mean()[0]-1)*100\n",
    "    y.columns = 'HOME_' + y.columns \n",
    "    y = y.reset_index()\n",
    "    z = temp2[temp2.HA == 'A'].groupby('OPP_TEAM')[['DKP']].mean()\n",
    "    z['League_Comparison'] = (z['DKP']/z.mean()[0]-1)*100\n",
    "    z.columns = 'AWAY_' + z.columns\n",
    "    z = z.reset_index()\n",
    "    temp2 = reduce(lambda left,right: pd.merge(left,right,on='OPP_TEAM'), [x,y,z])\n",
    "    temp2.columns = 'BY_POS_' + temp2.columns \n",
    "    temp2 = temp2.rename(columns={'BY_POS_OPP_TEAM': 'OPP_TEAM'})\n",
    "    teamDefbyPOS2[str(i)] = temp2\n",
    "    temp.loc[:, stats_cols] = temp.loc[:, stats_cols].div(temp.MIN, axis='index')*36\n",
    "    temp = temp.groupby('OPP_TEAM')[stats_cols].mean()\n",
    "    temp['FG_PCT'] = temp['FGM']/temp['FGA']\n",
    "    temp['FG3_PCT'] = temp['FG3M']/temp['FG3A']\n",
    "    temp['FT_PCT'] = temp['FTM']/temp['FTA']\n",
    "    temp.columns = 'DEF_BY_POS_' + temp.columns\n",
    "    teamDefbyPOS[str(i)] = temp.ix[:,1:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('http://www.cbssports.com/nba/injuries/daily')\n",
    "time.sleep(2)\n",
    "plyr = driver.find_elements_by_xpath('//*[@id=\"DailyTableData\"]/tr')\n",
    "injurylist = {'DATE': [], 'POS': [], 'PLAYER': [], 'TEAM': [], 'INJURY': [], 'EXPECTED_RETURN': []}\n",
    "for ply in plyr:\n",
    "    injurylist['DATE'].append(ply.find_element_by_xpath('.//td[1]/div').text)\n",
    "    injurylist['POS'].append(ply.find_element_by_xpath('.//td[2]/div').text)\n",
    "    injurylist['PLAYER'].append(ply.find_element_by_xpath('.//td[3]/div').text)\n",
    "    injurylist['TEAM'].append(ply.find_element_by_xpath('.//td[4]/div').text)\n",
    "    injurylist['INJURY'].append(ply.find_element_by_xpath('.//td[5]/div').text)\n",
    "    injurylist['EXPECTED_RETURN'].append(ply.find_element_by_xpath('.//td[6]/div').text)\n",
    "injurylist = pd.DataFrame(injurylist)\n",
    "injurylist['PLAYER'] = injurylist['PLAYER'].apply(namechange)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pastavgfortday(players, days, col):\n",
    "    return [playerGameLogs[i][col][:days].mean() for i in players]\n",
    "def getdefbypos(pos, opp):\n",
    "    new_df = pd.DataFrame({})\n",
    "    for i in range(len(opp)):\n",
    "        temp_df = pd.DataFrame({})\n",
    "        for j in pos[i]:\n",
    "            x = teamDefbyPOS[j].loc[teamDefbyPOS[j].OPP_TEAM == opp[i],:]\n",
    "            y = teamDefbyPOS2[j].loc[teamDefbyPOS2[j].OPP_TEAM == opp[i],:]\n",
    "            z = pd.merge(x,y, on= 'OPP_TEAM')\n",
    "            temp_df = pd.concat([temp_df,z], ignore_index= True)\n",
    "        temp_df = pd.DataFrame(temp_df.mean()).transpose()\n",
    "#         temp_df['OPP_TEAM'] = opp[i]\n",
    "        new_df = pd.concat([new_df, temp_df], ignore_index= True)\n",
    "    return new_df\n",
    "#function to get the data for todays players \n",
    "def gettodaysplayers():\n",
    "    date = pd.to_datetime('Today') #change date to 'today'\n",
    "    x = roto1[roto1.Date == date][['First  Last', 'Team', 'Opp', 'H/A', 'DK Sal', \\\n",
    "                                                      'DK Change', 'DK pos', 'Date']]\n",
    "    x = x[-x['DK Sal'].isnull()]\n",
    "    x.columns = ['PLAYER', 'TEAM', 'OPP_TEAM', 'HA', 'DK Sal', 'DK Change', 'DK pos', 'GAME_DATE']\n",
    "    x.PLAYER = x.PLAYER.apply(namechange)\n",
    "    x.TEAM = x.TEAM.apply(teamAbbrchange)\n",
    "    x.OPP_TEAM = x.OPP_TEAM.apply(teamAbbrchange)\n",
    "    players = []\n",
    "    for i in x.PLAYER:\n",
    "        if (not i in list(injurylist.PLAYER)): \n",
    "            if (i in playerGameLogs.keys()):\n",
    "                players.append(i)\n",
    "    x = x[[(i in players) for i in x.PLAYER]]\n",
    "    x['DK pos'] = x['DK pos'].astype(int).astype(str).str.join('@').str.split('@')\n",
    "    temp = x['DK pos'].str.join('@').str.get_dummies('@')\n",
    "    temp.columns = 'POSITION:' + temp.columns\n",
    "    x = pd.concat([x, temp], axis= 1)\n",
    "    x['DaysSinceLastGame'] = [(date - playerGameLogs[i]['GAME_DATE'][0]) for i in x.PLAYER]\n",
    "    x.loc[:, 'DaysSinceLastGame'] = (x.loc[:, 'DaysSinceLastGame']/np.timedelta64(1, 'D')).astype(int)\n",
    "    x = pd.concat([x.reset_index(drop=True), teamOppstats(list(x.TEAM), list(x.OPP_TEAM)).reset_index(drop=True)], axis = 1)\n",
    "    for i in stats_cols:\n",
    "        x['Past3_' + i] = pastavgfortday(x.PLAYER, 3, i)\n",
    "        x['Past6_' + i] = pastavgfortday(x.PLAYER, 6, i)\n",
    "        x['Avg_' + i] = pastavgfortday(x.PLAYER, 82, i) \n",
    "    x = pd.concat([x, getdefbypos(x['DK pos'], x.OPP_TEAM)], axis = 1)\n",
    "    x.loc[x.HA == 'A', 'BY_POS_HOME_DKP'] = x.loc[x.HA == 'A', 'BY_POS_AWAY_DKP']\n",
    "    x.loc[x.HA == 'A', 'BY_POS_HOME_League_Comparison'] = x.loc[x.HA == 'A', 'BY_POS_AWAY_League_Comparison']\n",
    "    x = x.rename(columns = {'BY_POS_HOME_DKP': 'BY_POS_ARENA_DKP', 'BY_POS_HOME_League_Comparison': 'BY_POS_ARENA_League_Comparison'})\n",
    "    x = x.drop(['BY_POS_AWAY_DKP', 'BY_POS_AWAY_League_Comparison'], axis = 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colstokeep = ['PLAYER', u'GAME_DATE', 'DaysSinceLastGame', 'HA', 'TEAM', 'OPP_TEAM', \\\n",
    "              'POSITION:1', 'POSITION:2', 'POSITION:3', 'POSITION:4', 'POSITION:5', 'Past3_MIN', 'Past6_MIN', 'Avg_MIN', \\\n",
    "              'Past3_FGM', 'Past6_FGM', 'Avg_FGM', 'Past3_FGA', 'Past6_FGA', 'Avg_FGA', 'Past3_FG_PCT', 'Past6_FG_PCT', \\\n",
    "              'Avg_FG_PCT', 'Past3_FG3M', 'Past6_FG3M', 'Avg_FG3M', 'Past3_FG3A', 'Past6_FG3A', 'Avg_FG3A', \\\n",
    "              'Past3_FG3_PCT', 'Past6_FG3_PCT', 'Avg_FG3_PCT', 'Past3_FTM', 'Past6_FTM', 'Avg_FTM', 'Past3_FTA', \\\n",
    "              'Past6_FTA', 'Avg_FTA', 'Past3_FT_PCT', 'Past6_FT_PCT', 'Avg_FT_PCT', 'Past3_OREB', 'Past6_OREB', 'Avg_OREB', \\\n",
    "              'Past3_DREB', 'Past6_DREB', 'Avg_DREB', 'Past3_REB', 'Past6_REB', 'Avg_REB', 'Past3_AST', 'Past6_AST', 'Avg_AST', \\\n",
    "              'Past3_STL', 'Past6_STL', 'Avg_STL', 'Past3_BLK', 'Past6_BLK', 'Avg_BLK', 'Past3_TOV', 'Past6_TOV', \\\n",
    "              'Avg_TOV', 'Past3_PF', 'Past6_PF', 'Avg_PF', 'Past3_PTS', 'Past6_PTS', 'Avg_PTS', 'Past3_PLUS_MINUS', \\\n",
    "              'Past6_PLUS_MINUS', 'Avg_PLUS_MINUS', 'Past3_DKP', 'Past6_DKP', 'Avg_DKP', 'Past3_DD', 'Past6_DD', 'Avg_DD', \\\n",
    "              'Past3_TD', 'Past6_TD', 'Avg_TD', u'TEAM_OPP_W_PCT', u'TEAM_OPP_MIN', u'TEAM_OPP_FGM', u'TEAM_OPP_FGA', \\\n",
    "              u'TEAM_OPP_FG_PCT', u'TEAM_OPP_FG3M', u'TEAM_OPP_FG3A', u'TEAM_OPP_FG3_PCT', u'TEAM_OPP_FTM', \\\n",
    "              u'TEAM_OPP_FTA', u'TEAM_OPP_FT_PCT', u'TEAM_OPP_OREB', u'TEAM_OPP_DREB', u'TEAM_OPP_REB', u'TEAM_OPP_AST', \\\n",
    "              u'TEAM_OPP_STL', u'TEAM_OPP_BLK', u'TEAM_OPP_TOV', u'TEAM_OPP_PF', u'TEAM_OPP_PTS', 'DEF_BY_POS_FGM', \\\n",
    "              'DEF_BY_POS_FGA', 'DEF_BY_POS_FG_PCT', 'DEF_BY_POS_FG3M', 'DEF_BY_POS_FG3A', 'DEF_BY_POS_FG3_PCT', \\\n",
    "              'DEF_BY_POS_FTM', 'DEF_BY_POS_FTA', 'DEF_BY_POS_FT_PCT', 'DEF_BY_POS_OREB', 'DEF_BY_POS_DREB', \\\n",
    "              'DEF_BY_POS_REB', 'DEF_BY_POS_AST', 'DEF_BY_POS_STL', 'DEF_BY_POS_BLK', 'DEF_BY_POS_TOV', 'DEF_BY_POS_PF', \\\n",
    "              'DEF_BY_POS_PTS', 'DEF_BY_POS_PLUS_MINUS', 'DEF_BY_POS_DKP', 'DEF_BY_POS_DD', 'DEF_BY_POS_TD', \\\n",
    "              'BY_POS_DKP', 'BY_POS_League_Comparison', 'BY_POS_ARENA_DKP', 'BY_POS_ARENA_League_Comparison', 'DKP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playerGameLogsModified = {}\n",
    "allPlayersGameLogsModified = pd.DataFrame({})\n",
    "for i in playerGameLogs.keys():\n",
    "    temp = playerGameLogs[i]\n",
    "    temp = pd.concat([temp, getdefbypos(temp['DK pos'], temp['OPP_TEAM'])], axis = 1)\n",
    "    temp.loc[temp.HA == 'A', 'BY_POS_HOME_DKP'] = temp.loc[temp.HA == 'A', 'BY_POS_AWAY_DKP']\n",
    "    temp.loc[temp.HA == 'A', 'BY_POS_HOME_League_Comparison'] = temp.loc[temp.HA == 'A', 'BY_POS_AWAY_League_Comparison']\n",
    "    temp = temp.rename(columns = {'BY_POS_HOME_DKP': 'BY_POS_ARENA_DKP', 'BY_POS_HOME_League_Comparison': 'BY_POS_ARENA_League_Comparison'})\n",
    "    temp = temp[colstokeep]\n",
    "    playerGameLogsModified[i] = temp\n",
    "    allPlayersGameLogsModified = pd.concat([allPlayersGameLogsModified, temp], ignore_index= True)\n",
    "    \n",
    "# for adding player position to players from different seasons\n",
    "# allPlayersGameLogsModified.to_csv('allPlayersGameLogsModified.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamelogs2016 = pd.read_csv('allPlayersGameLogsModified2015-16.csv')\n",
    "gamelogs2016.PLAYER = gamelogs2016.PLAYER + ' 2016'\n",
    "gamelogs2015 = pd.read_csv('allPlayersGameLogsModified2014-15.csv')\n",
    "gamelogs2015.PLAYER = gamelogs2015.PLAYER + ' 2015'\n",
    "playerAvgs2016 = pd.read_csv('playerAvgs2015-16.csv')\n",
    "playerAvgs2016.PLAYER = playerAvgs2016.PLAYER + ' 2016'\n",
    "playerAvgs2015 = pd.read_csv('playerAvgs2014-15.csv')\n",
    "playerAvgs2015.PLAYER = playerAvgs2015.PLAYER + ' 2015'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playerAvgsFinal = pd.concat([playerAvgs, playerAvgs2016, playerAvgs2015], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allPlayersGameLogsFinal = pd.concat([allPlayersGameLogsModified[colstokeep], gamelogs2016[colstokeep], \\\n",
    "                                     gamelogs2015[colstokeep]], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clustering function\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn import metrics\n",
    "# def cluster_players(n=10,df=playerAvgsFinal):\n",
    "#     df = df[df.AVG_DKP.isnull() == False]\n",
    "#     kmeans_model = KMeans(n_clusters=n, random_state=1)\n",
    "#     kmeans_model.fit(df.drop(['PLAYER','AVG_DKP'],axis=1))\n",
    "#     labels = kmeans_model.labels_+1\n",
    "#     return pd.concat([df,pd.DataFrame(labels,columns=['cluster'])],axis=1).sort_values('cluster')\n",
    "# player_clusters = cluster_players()[['PLAYER', 'cluster']]\n",
    "# player_clusters.to_csv('playerclusters.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create clusters\n",
    "#need to add clusters back to game logs\n",
    "player_clusters = pd.read_csv('playerclusters.csv')\n",
    "clusters = {}\n",
    "for i in range(1,11):\n",
    "    clusters[i] = player_clusters[player_clusters.cluster == i]['PLAYER'] \n",
    "# for i in range(player_clusters.shape[0]):\n",
    "#     clusters[player_clusters.PLAYER[i]] = player_clusters.cluster[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clustereddfs = {}\n",
    "# for i in clusters.keys():\n",
    "#     temp = pd.DataFrame({})\n",
    "#     for j in clusters[i]:\n",
    "#         temp = pd.concat([temp, playerGameLogsModified[j]], ignore_index= True)\n",
    "#     clustereddfs[i] = temp\n",
    "clustereddfs = {}\n",
    "injuryadjustment = {}\n",
    "for i in clusters.keys():\n",
    "    clustereddfs[i] = allPlayersGameLogsFinal[[(x in list(clusters[i])) for x in list(allPlayersGameLogsFinal.PLAYER)]]\n",
    "    temp = clustereddfs[i][clustereddfs[i].DaysSinceLastGame>10]\n",
    "    temp = temp[temp.Avg_DKP != 0]\n",
    "    injuryadjustment[i] = 1 + ((temp['DKP'] - temp['Avg_DKP'])/temp['Avg_DKP']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numericalcolumns = list(allPlayersGameLogsFinal.select_dtypes(include=[np.number]))\n",
    "droppedcols = [x for x in allPlayersGameLogsFinal.columns if (not x in numericalcolumns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corrtable(df, numcols = numericalcolumns):\n",
    "    a = []\n",
    "    for i in numcols:\n",
    "        b = pearsonr(df['DKP'], df[i])\n",
    "        a.append([i, b[0], b[1]])\n",
    "    a = pd.DataFrame(a)\n",
    "    a.columns = ['columns', 'correlation', 'pvalue']\n",
    "    a['abscorr'] = abs(a['correlation'])\n",
    "    a = a[a['pvalue'] <0.05]\n",
    "    a = a[a['abscorr'] != 1.0].sort_values(['abscorr'], ascending=[0])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjustedclusterdfs = {}\n",
    "clusteredcolumns = {}\n",
    "for i in clustereddfs.keys():\n",
    "    x = list(corrtable(clustereddfs[i])['columns'])\n",
    "    x = list(set(droppedcols + x + ['POSITION:1', 'POSITION:2', 'POSITION:3', 'POSITION:4', 'POSITION:5', 'DKP']))\n",
    "    clusteredcolumns[i] = [a for a in x if a != 'DKP']\n",
    "    adjustedclusterdfs[i] = clustereddfs[i][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gettoday = gettodaysplayers()\n",
    "todaysplayers = pd.merge(gettoday[colstokeep[:-1]], player_clusters, on='PLAYER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todaysclusters = {}\n",
    "# for i in clusters.keys():\n",
    "#     todaysclusters[i] = todaysplayers[todaysplayers.cluster == i].drop(['cluster'], axis = 1)\n",
    "todaysclusters = {}\n",
    "for i in clusters.keys():\n",
    "    todaysclusters[i] = todaysplayers[todaysplayers.cluster == i][clusteredcolumns[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjustplayersDKP = {}\n",
    "for i in todaysclusters.keys():\n",
    "    try:\n",
    "        temp = todaysclusters[i]\n",
    "        temp = temp[temp.DaysSinceLastGame > 10]\n",
    "        for j in temp.PLAYER:\n",
    "            adjustplayersDKP[j] = injuryadjustment[i]\n",
    "    except:\n",
    "        i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allPlayersGameLogs['Back'] = ((allPlayersGameLogs['POSITION:1'] + allPlayersGameLogs['POSITION:2']) > 0).astype(int)\n",
    "# allPlayersGameLogs['Front'] = ((allPlayersGameLogs['POSITION:3'] + allPlayersGameLogs['POSITION:4'] + allPlayersGameLogs['POSITION:5']) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = allPlayersGameLogs[['TEAM', 'Back', 'MIN']].groupby(['TEAM', 'Back']).sum().reset_index()\n",
    "z1 = allPlayersGameLogs[['TEAM', 'MIN']].groupby(['TEAM']).sum().reset_index()\n",
    "z1.columns = ['TEAM', 'TOT_MIN']\n",
    "z2 = pd.merge(z, z1, on='TEAM')\n",
    "z2['TOT_MIN_PER_GAME'] = z2.MIN/z2.TOT_MIN*240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playerstoignore = []\n",
    "playerstoignorefinal = []\n",
    "for i in injurylist.PLAYER:\n",
    "    try:\n",
    "        if ((pd.to_datetime('Today') - playerGameLogs[i].GAME_DATE[0])/np.timedelta64(1, 'D')).astype(int) <= 10:\n",
    "            playerstoignore.append(i)\n",
    "            playerstoignorefinal.append(i)\n",
    "    except:\n",
    "        playerstoignore.append(i)\n",
    "        playerstoignorefinal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players = {}\n",
    "for i in playerGameLogs.keys():\n",
    "    team = playerGameLogs[i].TEAM[0]\n",
    "    pos = int(round(allPlayersGameLogs[allPlayersGameLogs.PLAYER == i]['Back'].mean()))\n",
    "    past3mins = playerGameLogs[i].Avg_MIN[0]\n",
    "    players[i] = [team, past3mins, pos]\n",
    "    teamRoster[team][pos].append(i)\n",
    "    try:\n",
    "        if ((pd.to_datetime('Today') - playerGameLogs[i].GAME_DATE[0])/np.timedelta64(1, 'D')).astype(int) > 5:\n",
    "            playerstoignorefinal.append(i)\n",
    "    except:\n",
    "        playerstoignorefinal.append(i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teamstoupdate = []\n",
    "for i in playerstoignore:\n",
    "    try:\n",
    "        temp = [players[i][0], players[i][2]]\n",
    "        if temp not in teamstoupdate:\n",
    "            teamstoupdate.append(temp)\n",
    "    except:\n",
    "        i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teamstoupdate = [x for x in teamstoupdate if x[0] in list(set(gettoday.TEAM))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjustplayersmins = {}\n",
    "for i in teamstoupdate:\n",
    "    roster = set(teamRoster[i[0]][i[1]])\n",
    "    mins = z2[(z2.TEAM == i[0]) & (z2.Back == i[1])].reset_index().TOT_MIN_PER_GAME[0]\n",
    "    playr = []\n",
    "    plyrmins = 0\n",
    "    roster = [x for x in roster if ((x not in playerstoignorefinal) and x not in list(injurylist.PLAYER))]\n",
    "    for j in roster:\n",
    "        if players[j][1] > 25:\n",
    "            mins -= players[j][1]\n",
    "        else:\n",
    "            playr.append(j)\n",
    "            plyrmins += players[j][1]\n",
    "    for j in playr:\n",
    "        if (mins/plyrmins) < 0:\n",
    "            adjustplayersmins[j] = 0\n",
    "        elif (mins/plyrmins) > 1.5:\n",
    "            adjustplayersmins[j] = 1.5\n",
    "        else:\n",
    "            adjustplayersmins[j] = (mins/plyrmins)\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #linearreg\n",
    "# param_grid = {'alpha': sp_rand()}\n",
    "# #linear regression\n",
    "# linregpreds = pd.DataFrame()\n",
    "# # linregresults ={}\n",
    "# for i in range(1,11):\n",
    "#     temp = adjustedclusterdfs[i]\n",
    "#     x = temp[list(temp.select_dtypes(include=[np.number]))].drop(['DKP'], axis = 1)\n",
    "#     y = temp.DKP\n",
    "#     model = Ridge()\n",
    "#     rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, scoring= 'neg_mean_squared_error', n_iter=100)\n",
    "#     rsearch.fit(x, y)\n",
    "#     best = rsearch.best_estimator_\n",
    "# #     para_search = gs.GridSearchCV(ols, para_grid, scoring='neg_mean_squared_error', cv =5).fit(x, y)\n",
    "# #     best = para_search.best_estimator_\n",
    "# #     best.fit(x,y)\n",
    "# #     colnames = x.columns\n",
    "# #     result = pd.DataFrame(ols.coef_).transpose()\n",
    "# #     result.columns = colnames.tolist()\n",
    "# #     result['intercept'] = ols.intercept_ \n",
    "# #     result = result.transpose()\n",
    "# #     result.columns = ['coefficient']\n",
    "# #     linregresults[i] =result \n",
    "#     temp2 = temp[['PLAYER', 'DKP']]\n",
    "#     temp2['PREDS'] = best.predict(x)\n",
    "#     linregpreds = linregpreds.append(temp2)\n",
    "# sqrt(((linregpreds.PREDS-linregpreds.DKP)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #NN\n",
    "# seed = 7\n",
    "# numpy.random.seed(seed)\n",
    "# dataset = allPlayersGameLogsFinal\n",
    "# dataset.GAME_DATE = pd.to_datetime(dataset.GAME_DATE)\n",
    "# numcols = list(dataset.select_dtypes(include=[np.number]))\n",
    "# categorical = [x for x in dataset.columns if (not x in numcols) ]\n",
    "# for f in categorical[2:]:\n",
    "#     lbl = preprocessing.LabelEncoder()\n",
    "#     lbl.fit(list(dataset[f].values))\n",
    "#     dataset[f] = lbl.transform(list(dataset[f].values))\n",
    "# dataset = shuffle(dataset)\n",
    "# X = dataset.loc[:, list(dataset)[:-1]]\n",
    "# Y = dataset.loc[:, 'DKP']\n",
    "# a = pd.concat([X[['PLAYER', 'GAME_DATE']], Y], axis = 1)\n",
    "# X = X.loc[:,X.columns[2:]].as_matrix()\n",
    "# X = StandardScaler().fit(X).transform(X)\n",
    "# Y = Y.as_matrix()/70\n",
    "# # create model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(200, input_dim=len(dataset.columns) - 3, init='uniform', activation='sigmoid'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(20, init='uniform', activation='sigmoid'))\n",
    "# model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "# history = model.fit(X, Y, nb_epoch=1000, batch_size=10, validation_split= 0.2, callbacks=[EarlyStopping(patience= 20, min_delta=1e-5)])\n",
    "# predictions = model.predict(X)*70\n",
    "# x = pd.concat([a.reset_index(drop=True), pd.DataFrame(predictions), ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def xgb_evaluate(min_child_weight,\n",
    "#                  colsample_bytree,\n",
    "#                  max_depth,\n",
    "#                  subsample,\n",
    "#                  gamma,\n",
    "#                  lamb):\n",
    "#     params['objective'] = 'reg:linear'\n",
    "#     params['min_child_weight'] = int(min_child_weight)\n",
    "#     params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "#     params['max_depth'] = int(max_depth)\n",
    "#     params['subsample'] = max(min(subsample, 1), 0)\n",
    "#     params['gamma'] = max(gamma, 0)\n",
    "#     params['lambda'] = max(lamb, 0)\n",
    "\n",
    "\n",
    "#     cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,\n",
    "#              seed=random_state,\n",
    "#              callbacks=[xgb.callback.early_stop(20)])\n",
    "\n",
    "#     return -cv_result['test-rmse-mean'].values[-1]\n",
    "\n",
    "\n",
    "# def prepare_data(i):\n",
    "#     train = adjustedclusterdfs[i].drop(['GAME_DATE'], axis = 1)\n",
    "#     categorical_columns = train.select_dtypes(include=['object']).columns\n",
    "\n",
    "#     for column in tqdm(categorical_columns):\n",
    "#         le = LabelEncoder()\n",
    "#         train[column] = le.fit_transform(train[column])\n",
    "\n",
    "#     y = train['DKP']\n",
    "\n",
    "#     X = train.drop(['DKP', 'PLAYER'], 1)\n",
    "#     xgtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "#     return xgtrain\n",
    "\n",
    "# num_rounds = 3000\n",
    "# random_state = 0\n",
    "# num_iter = 25\n",
    "# init_points = 5\n",
    "# params = {\n",
    "#     'eta': 0.01,\n",
    "#     'silent': 1,\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'verbose_eval': True,\n",
    "#     'seed': random_state\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bestparams = {}\n",
    "# for i in range(1,11):\n",
    "#     xgtrain = prepare_data(i)\n",
    "\n",
    "\n",
    "#     xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "#                                                 'colsample_bytree': (0.1, 1),\n",
    "#                                                 'max_depth': (5, 15),\n",
    "#                                                 'subsample': (0.5, 1),\n",
    "#                                                 'gamma': (0, 10),\n",
    "#                                                 'lamb': (0, 10),\n",
    "#                                                 })\n",
    "\n",
    "#     xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "#     bestparams[i] = xgbBO.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bestparams = pd.DataFrame(bestparams).reset_index()\n",
    "# bestparams = bestparams.rename(columns = {'index': 'params'})\n",
    "# bestparams.to_csv('xgboostbestparams.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestparams =pd.read_csv('xgboostbestparams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "for i in range(1,11):\n",
    "    params[i] = {}\n",
    "    n = 0\n",
    "    for j in bestparams.params:\n",
    "        params[i][j] = bestparams[str(i)][n]\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(colsample_bytree, gamma, lamb, max_depth, min_child_weight, subsample, \\\n",
    "           train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=3000):\n",
    "    param = {}\n",
    "    param['objective'] = 'reg:linear'\n",
    "    param['eta'] = 0.01\n",
    "    param['max_depth'] = max_depth\n",
    "    param['gamma'] = gamma\n",
    "    param['silent'] = 1\n",
    "    param['lambda'] = lamb\n",
    "    param['eval_metric'] = \"rmse\"\n",
    "    param['min_child_weight'] = min_child_weight\n",
    "    param['subsample'] = subsample\n",
    "    param['colsample_bytree'] = colsample_bytree\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royh21k/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "TRAIN = {}\n",
    "TRAINTARGET = {}\n",
    "TEST = {}\n",
    "\n",
    "for i in adjustedclusterdfs.keys():\n",
    "    \n",
    "    categorical = ['HA']\n",
    "    for f in categorical:\n",
    "#         if train[f].dtype=='object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(adjustedclusterdfs[i][f].values))\n",
    "        adjustedclusterdfs[i][f] = lbl.transform(list(adjustedclusterdfs[i][f].values))\n",
    "        todaysclusters[i][f] = lbl.transform(list(todaysclusters[i][f].values))\n",
    "    \n",
    "#     TRAIN[i] =clustereddfs[i][clustereddfs[i].GAME_DATE != pd.to_datetime('2017-03-16')].drop('DKP',axis=1)\n",
    "#     TRAINTARGET[i] = clustereddfs[i][clustereddfs[i].GAME_DATE != pd.to_datetime('2017-03-16')]['DKP']\n",
    "#     TEST[i] = clustereddfs[i][clustereddfs[i].GAME_DATE == pd.to_datetime('2017-03-16')].drop('DKP',axis=1)\n",
    "    \n",
    "    TRAIN[i] =adjustedclusterdfs[i].drop(['DKP'], axis = 1)\n",
    "    TRAINTARGET[i] = adjustedclusterdfs[i]['DKP']\n",
    "    TEST[i] = todaysclusters[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cluster  1\n",
      "training cluster  2\n",
      "training cluster  3\n",
      "training cluster  4\n",
      "training cluster  5\n",
      "training cluster  6\n",
      "training cluster  7\n",
      "training cluster  8\n",
      "training cluster  9\n",
      "training cluster  10\n"
     ]
    }
   ],
   "source": [
    "todayspreds = pd.DataFrame()\n",
    "for i in clustereddfs.keys():\n",
    "        \n",
    "    x_train = TRAIN[i].drop(['PLAYER','GAME_DATE','TEAM','OPP_TEAM'],axis=1)\n",
    "    y_train = TRAINTARGET[i]\n",
    "    x_test = TEST[i].drop(['PLAYER','GAME_DATE','TEAM','OPP_TEAM'],axis=1)\n",
    "    \n",
    "    print 'training cluster ',str(i)\n",
    "    pred, model = runXGB(params[i]['colsample_bytree'], params[i]['gamma'], params[i]['lamb'],int(params[i]['max_depth']), \\\n",
    "                         params[i]['min_child_weight'], params[i]['subsample'], x_train, y_train, x_test)\n",
    "    model.save_model('cluster'+str(i)+'.model')\n",
    "    \n",
    "    temp = pd.concat([pd.DataFrame(pred),TEST[i]\\\n",
    "                      .reset_index(drop=True)\\\n",
    "                      [['PLAYER','GAME_DATE','POSITION:1','POSITION:2','POSITION:3','POSITION:4','POSITION:5']]],axis=1)\n",
    "    todayspreds = todayspreds.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todayspreds = pd.merge(todayspreds, gettoday[['PLAYER', 'DK Sal']], on= 'PLAYER')\n",
    "todayspreds['minmult'] = todayspreds.PLAYER.apply(lambda x: 1 if x not in adjustplayersmins.keys() else adjustplayersmins[x])\n",
    "todayspreds['DKPmult'] = todayspreds.PLAYER.apply(lambda x: 1 if x not in adjustplayersDKP.keys() else adjustplayersDKP[x])\n",
    "todayspreds['predadjust'] = todayspreds[0]*todayspreds.minmult*todayspreds.DKPmult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predsforskewdness = {}\n",
    "for i in range(1,11):\n",
    "    model = xgb.Booster()\n",
    "    model.load_model('cluster'+str(i)+'.model') # load data\n",
    "    x_test = xgb.DMatrix(TRAIN[i].drop(['PLAYER','GAME_DATE','TEAM','OPP_TEAM'],axis=1))\n",
    "    pred = model.predict(x_test)\n",
    "    temp = pd.concat([pd.DataFrame(pred),adjustedclusterdfs[i]\\\n",
    "                      .reset_index(drop=True)\\\n",
    "                      [['PLAYER','GAME_DATE','POSITION:1','POSITION:2','POSITION:3','POSITION:4','POSITION:5', 'DKP']]],axis=1)\n",
    "    predsforskewdness[i] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skewness_dict = {}\n",
    "# kurtosis_dict = {}\n",
    "# for i in set(allPlayersGameLogsFinal.PLAYER):\n",
    "#     #print name\n",
    "#     temp = allPlayersGameLogsFinal[allPlayersGameLogsFinal.PLAYER == i]\n",
    "#     skewness_dict[i] = stats.skew(temp.DKP)\n",
    "#     kurtosis_dict[i] = stats.kurtosis(temp.DKP)\n",
    "# skew_df1 = pd.DataFrame(kurtosis_dict, index = ['Kurtosis'])\n",
    "# skew_df2 = pd.DataFrame(skewness_dict, index = ['Skewness'])\n",
    "# skewness_df = pd.concat([skew_df1, skew_df2], axis = 0).T.reset_index().rename(columns= {'index': 'PLAYER'})\n",
    "# skewness_df.to_csv('skewness.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skewness_df = pd.read_csv('skewness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'alpha': np.logspace(-2, 5, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royh21k/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "results ={}\n",
    "# skewpreds = pd.DataFrame()\n",
    "for i in range(1,11):\n",
    "    temp = pd.merge(predsforskewdness[i][['PLAYER', 'DKP', 0]], skewness_df, on = 'PLAYER', how= 'left')\n",
    "    temp = temp.rename(columns = {0:'PREDS'})\n",
    "    temp.Kurtosis = temp.Kurtosis * temp['PREDS']\n",
    "    temp.Skewness = temp.Skewness * temp['PREDS']\n",
    "    x = temp[['PREDS', 'Kurtosis', 'Skewness']]\n",
    "    y = temp.DKP\n",
    "    model = Ridge()\n",
    "    rsearch = gs.GridSearchCV(estimator=model, param_grid=param_grid, scoring= 'neg_mean_squared_error')\n",
    "    rsearch.fit(x, y)\n",
    "    best = rsearch.best_estimator_\n",
    "#     temp2 = temp[['PLAYER', 'DKP']]\n",
    "#     temp2['PREDS'] = best.predict(x)\n",
    "#     skewpreds = skewpreds.append(temp2)\n",
    "    colnames = x.columns\n",
    "    result = pd.DataFrame(best.coef_).transpose()\n",
    "    result.columns = colnames.tolist()\n",
    "    result['intercept'] = best.intercept_ \n",
    "    result = result.transpose()\n",
    "    result.columns = ['coefficient']\n",
    "    results[i] =result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "todays = pd.merge(todayspreds, skewness_df, on = 'PLAYER', how= 'left')\n",
    "todays = todays.rename(columns= {0:'PREDS'})\n",
    "todays.Kurtosis = todays.Kurtosis * todays.PREDS\n",
    "todays.Skewness = todays.Skewness * todays.PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todays = pd.merge(todays, player_clusters, on= 'PLAYER', how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royh21k/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "todayskewness = pd.DataFrame()\n",
    "for i in range(1,11):\n",
    "    temp = todays[todays.cluster == i]\n",
    "    temp['adjust'] = temp.PREDS* results[i]['coefficient'][0] + temp.Kurtosis * results[i]['coefficient'][1]  + \\\n",
    "                    temp.Skewness * results[i]['coefficient'][2] + results[i]['coefficient'][3]\n",
    "    todayskewness = todayskewness.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todayspreds = pd.merge(todayspreds, todayskewness[['PLAYER', 'adjust']], on= 'PLAYER', how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todayspreds['finaladjust'] = todayspreds.adjust * todayspreds.minmult * todayspreds.DKPmult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeseries = pd.read_csv('GamePredictions.csv')\n",
    "timeseries = timeseries.rename(columns = {'Player': 'PLAYER'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "todayspreds = pd.merge(todayspreds, timeseries[['PLAYER', 'AR Predictions', 'EWMA Predictions']], on= 'PLAYER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todayspreds = todayspreds.rename(columns= {0:'PREDS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todayspreds.to_csv(str(pd.to_datetime('today'))[:10]+'preds.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "todayspreds = pd.merge(todayspreds[['PLAYER', 'DK Sal', 'PREDS', 'predadjust', 'adjust', 'finaladjust', 'AR Predictions', 'EWMA Predictions']], \n",
    "         todaysplayers, on= 'PLAYER', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "todayspreds.to_csv(str(pd.to_datetime('today'))[:10]+'preds.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
